{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf version: 1.4.0\n"
     ]
    }
   ],
   "source": [
    "#Please change the Kernel to tensorflow_p27\n",
    "#Unfortunately, the webcam version will not work on AWS. \n",
    "#If you want to try the realtime video, you may download the code from my github. You need a GPU machine and tensorflow installed. \n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, 'src')\n",
    "\n",
    "import os, random, subprocess, evaluate, shutil\n",
    "import pdb\n",
    "\n",
    "import transform, numpy as np, vgg\n",
    "import scipy.misc\n",
    "import tensorflow as tf\n",
    "from utils import save_img, get_img, exists, list_files\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import json\n",
    "import subprocess\n",
    "import natsort\n",
    "\n",
    "print(\"tf version:\",tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir='./models/ckpt_cubist_b20_e4_cw05' # the saved style transformation model\n",
    "path_video_in='./video_in/test_video.mp4' # the input video\n",
    "\n",
    "# the output videl will be saved here. If this video already exists, delete it. \n",
    "path_video_out='./video_out/video2.mp4'\n",
    "\n",
    "# this folder will be used to store the frames\n",
    "tmp_dir= './tmpdir_frames/'\n",
    "\n",
    "# GPU id\n",
    "device='/gpu:0'\n",
    "\n",
    "# this many images will be processed in one batch\n",
    "batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tmpdir_frames/in\n",
      "./tmpdir_frames/out\n"
     ]
    }
   ],
   "source": [
    "# input frames will be stored here\n",
    "in_dir = os.path.join(tmp_dir, 'in')\n",
    "\n",
    "# output frames will be stored here\n",
    "out_dir = os.path.join(tmp_dir, 'out')\n",
    "\n",
    "if not os.path.exists(in_dir):\n",
    "    os.makedirs(in_dir)\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "    \n",
    "print(in_dir)\n",
    "print(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us use ffmpeg to get the frames from the video\n",
    "in_args = [\n",
    "    'ffmpeg',\n",
    "    '-i', path_video_in,\n",
    "    '%s/frame_%%d.png' % in_dir\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call(\" \".join(in_args), shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_1.png ,..., frame_884.png\n",
      "./tmpdir_frames/in\n",
      "./tmpdir_frames/out/frame_1.png ,..., ./tmpdir_frames/out/frame_884.png\n"
     ]
    }
   ],
   "source": [
    "base_names = natsort.natsorted(list_files(in_dir))\n",
    "print(base_names[0],',...,', base_names[-1])\n",
    "\n",
    "print(in_dir)\n",
    "in_files = [os.path.join(in_dir, x) for x in base_names]\n",
    "out_files = [os.path.join(out_dir, x) for x in base_names]\n",
    "\n",
    "print(out_files[0],',...,',out_files[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate.ffwd(in_files, out_files, checkpoint_dir, device_t=device, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 854, 3)\n"
     ]
    }
   ],
   "source": [
    "assert len(out_files) > 0\n",
    "#is_paths = type(in_files[0]) == str\n",
    "\n",
    "img_shape = get_img(in_files[0]).shape\n",
    "print(img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_shape (4, 480, 854, 3)\n",
      "INFO:tensorflow:Restoring parameters from ./models/ckpt_cubist_b20_e4_cw05/fns.ckpt\n",
      " transformed image: 100 / 100"
     ]
    }
   ],
   "source": [
    "# Create a tensorflow graph\n",
    "g = tf.Graph()\n",
    "batch_size = min(len(out_files), batch_size)\n",
    "soft_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "soft_config.gpu_options.allow_growth = True\n",
    "\n",
    "with g.as_default(), g.device(device), tf.Session(config=soft_config) as sess:\n",
    "        \n",
    "        #the current batch will have these dimensions\n",
    "        batch_shape = (batch_size,) + img_shape\n",
    "        print(\"batch_shape\", batch_shape)\n",
    "        \n",
    "        # image input of the nural network\n",
    "        img_placeholder = tf.placeholder(tf.float32, shape=batch_shape, name='img_placeholder')\n",
    "        \n",
    "        # the output image of the neural network\n",
    "        preds = transform.net(img_placeholder)\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        if os.path.isdir(checkpoint_dir):\n",
    "            ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                # load the current model!\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            else:\n",
    "                raise Exception(\"No checkpoint found...\")\n",
    "        else:\n",
    "            raise Exception(\"No checkpoint directory found...\")\n",
    "            #saver.restore(sess, checkpoint_dir)\n",
    "        \n",
    "        # We are going to trasnfer the style of num_iters*batch_size frames\n",
    "        #num_iters = int(len(out_files)/batch_size)\n",
    "        num_iters=100\n",
    "\n",
    "        # main loop starts\n",
    "        for i in range(num_iters):\n",
    "            sys.stdout.write(\"\\r transformed image: %d / %d\" % (i+1, num_iters))\n",
    "            sys.stdout.flush()\n",
    "    \n",
    "            pos = i * batch_size\n",
    "            curr_batch_out = out_files[pos:pos+batch_size]\n",
    "            curr_batch_in = in_files[pos:pos+batch_size]\n",
    "            \n",
    "            # Let us create the input of the neural network\n",
    "            X = np.zeros(batch_shape, dtype=np.float32)\n",
    "            for j, path_img_in in enumerate(curr_batch_in):\n",
    "                # get the image from the file name\n",
    "                img = get_img(path_img_in)\n",
    "                assert img.shape == img_shape,'Images have different dimensions. ' +'Resize images or use --allow-different-dimensions.'\n",
    "                X[j] = img\n",
    "            \n",
    "            # do the style transform! Put the results into preds placeholder\n",
    "            _preds = sess.run(preds, feed_dict={img_placeholder:X})\n",
    "            \n",
    "            # save the results\n",
    "            for j, path_img_out in enumerate(curr_batch_out):\n",
    "                save_img(path_img_out, _preds[j])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a movie from the saved frames\n",
    "# out[10]: 0 means it's been successfully excuted\n",
    "# as you can see in the code, you can find your video in the video_out folder. You may download and watch it. \n",
    "\n",
    "fr = 30 \n",
    "out_args = [\n",
    "    'ffmpeg',\n",
    "    '-i', '%s/frame_%%d.png' % out_dir,\n",
    "    '-f', 'mp4',\n",
    "    '-q:v', '0',\n",
    "    '-vcodec', 'mpeg4',\n",
    "    '-r', str(fr),\n",
    "    path_video_out\n",
    "]\n",
    "\n",
    "subprocess.call(\" \".join(out_args), shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video at: ./video_out/video2.mp4\n"
     ]
    }
   ],
   "source": [
    "print('Video at: %s' % path_video_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the tmp folder\n",
    "shutil.rmtree(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
